---
layout: post
title: "17. Paper Review: Learning to Generate Question by Asking Question: A Primal-Dual Approach with Uncommon Word Generation@EMNLP'2022"
# date: 2016-06-19 10:00:00 +0900
categories: review
# tags: [LSTM, Anomaly Detection, ICML, Deep Learning]
---
[Paper Link](https://aclanthology.org/2022.emnlp-main.4.pdf)

# Abstract
이 논문은 주어진 지문과 답변으로부터 질문을 생성하는 자동 질문 생성(AQG) 작업에 대한 새로운 접근 방식을 제안한다. 대부분의 기존 AQG 방법은 지문과 답변을 인코딩하여 질문을 생성하는 데 중점을 두지만 , 이 논문은 대상 답변과 생성된 질문 간의 상관관계를 모델링하고 이전 연구에서 다루지 않았던 새롭거나 희귀한 단어 생성에 초점을 맞추고 있다.

이 논문에서 제안하는 접근 방식은 질문 생성과 그 역 문제인 질문 응답을 통합한 통합된 프라이멀-듀얼(primal-dual) 프레임워크를 사용한다. 구체적으로, 질문 생성 구성 요소는 답변과 지문을 함께 인코딩하는 인코더와 질문을 생성하는 디코더로 구성된다. 질문 응답 구성 요소는 생성된 질문을 지문에 다시 질문하여 대상 답변이 얻어지는지 확인한다. 또한, 모델의 일반화 능력을 향상시키기 위해 지식 증류(knowledge distillation) 모듈을 도입한다. SQUAD 및 HotpotQA 벤치마크에 대한 실험 결과는 제안된 접근 방식이 여러 SOTA 방법보다 우수한 성능을 보임을 입증한다.

# Introduction
![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_2.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_3.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_4.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_5.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_6.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_7.png)

# Proposed Method
![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_8.png)
![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_9.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_10.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_11.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_12.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_13.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_14.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_15.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_16.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_17.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_18.png)

# Experiments
![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_19.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_20.png)
![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_21.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_22.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_23.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_24.png)![image](/images/Learning to Generate Question by Asking Question/Learning to Generate Question by Asking Question_25.png)

# Conclusion and Review
* Question Generation task에 새로운 **primal-dual approach** 제안
	* Question generation을 **dual problem인 question answering**과 unified framework로 **통합**
* **Knowledge distillation** module로 model의 **generalization을 향상**
	* Uncommon word generation
* 실험적으로 primal-dual modeling의 effectiveness를 보여줌
	* SQuAD, HotpotQA
* Question answering task를 question generation 결과에 대한 일종의 verification으로 사용(단일 모델로 활용)
* Knowledge distillation module의 uncommon word generation은 활용 가능할 것 같음
	* Manual dataset을 활용하여 context 내에서 다양한 entity들을 masking하여 학습(with additional model)
