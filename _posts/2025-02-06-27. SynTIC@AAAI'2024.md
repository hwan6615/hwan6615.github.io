---
layout: post
title: "27. Paper Review: Improving Cross-Modal Alignment with Synthetic Pairs for Text-Only Image Captioning@AAAI'2024"
# date: 2016-06-19 10:00:00 +0900
categories: review
# tags: [LSTM, Anomaly Detection, ICML, Deep Learning]
---
[Paper Link](https://arxiv.org/pdf/2312.08865)

# Abstract
이미지와 텍스트 쌍으로 구성된 고품질 데이터셋의 높은 의존성을 해결하기 위한 텍스트 전용 이미지 캡셔닝 방법인 SynTIC을 제안한다.

-   **합성 이미지-텍스트 쌍 활용**: 사전 학습된 텍스트-이미지 모델을 사용하여 텍스트 데이터에 해당하는 이미지를 생성한다.
    
-   **Improving Cross-modal alignment**: 생성된 이미지의 특징은 CLIP 임베딩 공간에서 실제 이미지의 특징에 가깝게 최적화된다. 또한, 이미지 특징을 표현하기 위해 텍스트 정보를 수집하여 다양한 의미를 가진 이미지 특징을 생성하고 모달리티 간극을 연결한다.
    
-   **훈련과 추론의 통일**: 합성 이미지 특징이 언어 디코더의 training prefix로 사용되고, 실제 이미지는 추론에 사용되어 훈련과 추론 간의 불일치를 해소한다.

# Introduction
![image](/images/SynTic review/SynTic review_3.png)
![image](/images/SynTic review/SynTic review_4.png)![image](/images/SynTic review/SynTic review_5.png)![image](/images/SynTic review/SynTic review_6.png)![image](/images/SynTic review/SynTic review_7.png)![image](/images/SynTic review/SynTic review_8.png)

# Proposed Methods
![image](/images/SynTic review/SynTic review_10.png)
![image](/images/SynTic review/SynTic review_11.png)![image](/images/SynTic review/SynTic review_12.png)![image](/images/SynTic review/SynTic review_13.png)![image](/images/SynTic review/SynTic review_14.png)![image](/images/SynTic review/SynTic review_15.png)![image](/images/SynTic review/SynTic review_16.png)![image](/images/SynTic review/SynTic review_17.png)![image](/images/SynTic review/SynTic review_18.png)![image](/images/SynTic review/SynTic review_19.png)

# Experiments
![image](/images/SynTic review/SynTic review_21.png)
![image](/images/SynTic review/SynTic review_22.png)![image](/images/SynTic review/SynTic review_23.png)![image](/images/SynTic review/SynTic review_24.png)![image](/images/SynTic review/SynTic review_26.png)
![image](/images/SynTic review/SynTic review_27.png)
![image](/images/SynTic review/SynTic review_28.png)

# Conclusion and Review
* Synthetic image를 생성하여 training, inference를 통합
* Generation-then-refinement로 실제 이미지와의 gap을 줄임
* Feature projection으로 text 정보를 pseudo image 정보에 녹임
* 이미지를 사용해서 얻는 효과가 큼
	* Supervised setting, object 정보 사용 가능, cross-modal alignment
	* 기존 방식과 다르게 명확한 modality gap을 줄이는 방식
* Text-image model(diffusion model)의 성능이 굉장히 중요
